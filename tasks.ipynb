{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical functions from the standard library.\n",
    "# https://docs.python.org/3/library/math.html\n",
    "import math\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels as sm\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "## Lady Tasting Tea\n",
    "\n",
    "An event in Fisher's life led him to design this experiment, His friend's future wife, Muriel Bristol, said that she could tell if the tea or the milk was put first into a cup. She was given eight cups, four of them created each way and given to her in random order. Fisher wanted to find the probability that she could say the order of addition to the cup. In the end, Muriel correctly identified which of the four cups of tea had milk poured before the tea.\n",
    "\n",
    "Problem Statement\n",
    "Suppose the Lady Tasting Tea experiment is altered to involve twelve cups of tea. Six have the milk in first and the other six having tea in first. A person claims that they have the special power of being able to tell if the tea or the milk went into a cup first upon tasting it. You agree to accept their claim if they can tell which of the six cups in your experiment had the milk in first.\n",
    "1.\tCalculate, using Python, the probability that they select the correct six cups.\n",
    "Suppose, now, you are willing to accept one error. Once they select the six cups they think had the milk in first, you will give them the benefit of the doubt should they have selected at least five of the correct cups.\n",
    "2.\tCalculate the probability, assuming they have no special powers, that the person makes at most one error.\n",
    "3.\tWould you accept two errors? Explain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some assumptions to take into account for this test, we do this to try to ensure we taken out the element of chance and we are relying on statistical derivation. \n",
    "1. The lady is just guessing which way the milk was poured and cannot tell either way. This will follow the null hypothesis as her having np ability to tell the difference\n",
    "2. Once a cup has been selected, it is not put back into the selection so it cannot be chosen twice or more times\n",
    "3. It doesn't matter what way she does it, but she has to correctly state which way the milk was poured from her choice of 6 cups   from the 12.\n",
    "4. We assume that she can tell the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, we will be using 12 cups of tea as the test. We can start by assigning the total number of cups to a variable and then split the total in two, to have variables with the number of cups having milk poured in before the tea and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of cups.\n",
    "cups = 12\n",
    "\n",
    "# Milk first.\n",
    "milk_first = 6\n",
    "\n",
    "# Tea first.\n",
    "tea_first = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show that from 12 cups, there is a possibility of choosing 1 from 12 choices, that leaves 11 cups to choose from. 1 out of 11 leaves 10 and so on.\n",
    "So, there are 12 x 11 x 10 x 9 x 8 x 7 choices of cup as the test progresses. After 6 cups have been selected the rest are ignored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total ways of selecting 6 random cups.\n",
    "selection = math.comb(cups, milk_first)\n",
    "\n",
    "# Display total number of possible selections.\n",
    "selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how many permutations there are of selecting 6 cups from 12, we want to see the number ways we can randomise the presentation of the cups to the tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many chances are there that the lady will select correctly out of the 6 cups.\n",
    "correct = 6 * 5 * 4 * 3 * 2 * 1\n",
    "\n",
    "# Display total number of possible selections.\n",
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show how the random selection of 6 cups could be presented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we give the cups an identifier\n",
    "identify = list(range(cups))\n",
    "\n",
    "identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using python, we can create a list of all the combinations that can be chosen from 12 cups. As shown previously,\n",
    "# there should be 924 combinations.\n",
    "user_combinations = list(itertools.combinations(identify, milk_first))\n",
    "\n",
    "user_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many possible combinations are there\n",
    "len(user_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milk_identify = random.sample(identify, 6)\n",
    "#sort them in order\n",
    "milk_identify.sort()\n",
    "\n",
    "milk_identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the list, user_combinations, into a set, comb, so that there are no repetitions  \n",
    "num_of_overlaps = []\n",
    "\n",
    "for comb in user_combinations: # https://www.geeksforgeeks.org/python-math-comb-method/\n",
    "    s1 = set(comb)\n",
    "    s2 = set(milk_identify)\n",
    "# show where the sets overlap\n",
    "overlap = s1.intersection(s2)\n",
    "# print(comb, overlap)\n",
    "num_of_overlaps.append(len(overlap))\n",
    "\n",
    "print(num_of_overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.unique(num_of_overlaps, return_counts=True)\n",
    "\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the plots\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.bar(values[0], values[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The probability of selecting 6 cups correctly from 12 is given below\n",
    "probability = 1 / selection\n",
    "\n",
    "percentage = probability * 100\n",
    "\n",
    "print(f'The probability for the first 6 cups to be identifiedcorrectly is {probability} which is {percentage}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we can see that the chance of selecting the six cups with milk poured first from 12 cups is 1 in 924.\n",
    "Or 1/924 which gives us a probability of 0.001 (rounded down) or 0.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the probability of making at least one error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of selecting exactly 5 correct cups\n",
    "\n",
    "five_right = math.comb(6, 5) * math.comb(6, 1)\n",
    "\n",
    "\n",
    "probability_5 = five_right / selection\n",
    "\n",
    "percentage_5 = probability_5 * 100\n",
    "probability_5\n",
    "print(f'The probability for the subject to identify 5 cups correctly is {probability_5} or {percentage_5:.1f} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decide if we can accept two errors as reasonable, we have to calculate the probability of selecting 4 of the cups correctly out of 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_right = math.comb(6, 4) * math.comb(6, 2)\n",
    "\n",
    "probability_4 = four_right / selection\n",
    "\n",
    "percentage_4 = probability_4 * 100\n",
    "\n",
    "print(f'The probability for the subject to identify 4 cups correctly is {probability_4} or {percentage_4:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the lady has a 24.4 % chance to select the cups with 2 errors allowed, 3.9 % to select with 1 error and 0.1 % to select all 6 cups correctly out of 12.\n",
    "\n",
    "We carry out the statistical tests to see if the claim can be verified. \n",
    "If not, we call it the Null Hypothesis, whereby we can not find any statistics to prove the claim is correct. In our experiment, the Null hypothesis (H₀) would indicate to us that Muriel cannot reliably discern if milk is put in first to the cup or not. We try to ensure she selects the six cups from the twelve cups at random.\n",
    "Alternative hypothesis (H₁): She can tell the difference between cups with the milk in first or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 \n",
    "\n",
    "## Numpy's Normal Distribution\n",
    "\n",
    "Task 2 is to assess whether `numpy.random.normal()` properly generates normal values.\n",
    "To start, we generate a sample of one hundred thousand values using the function with mean `10.0` and standard deviation `3.0`.\n",
    "\n",
    "Use the `scipy.stats.shapiro()` function to test whether the sample came from a normal distribution.\n",
    "Explain the results and output.\n",
    "\n",
    "Plot a histogram of the values and plot the corresponding normal distribution probability density function on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "n = 100000 # number of values\n",
    "mu = 10.0 # mean value\n",
    "sigma = 3.0 # Standard Deviation\n",
    "n_bins = 30\n",
    "# from lecture data = np.random.normal(size=100000)\n",
    "# loc is mean of distrib, scale is the standard deviation so code is random.normal(loc=0.0, scale = 1.0, size = 100000)\n",
    "\n",
    "sample = np.random.normal(loc=10.0, scale = 3.0, size = 100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histogram of the data to assess how near to the normal distribution it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot histogram of the data\n",
    "ax.hist(sample, bins=n_bins)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, we can see that the data appears to be fairly normally distributed. Next we can use a q-q plot, to give us some confirmation that the data is relatively normally distributed. We can see the majority of the data we created (blue dots) lies on the computed line(red line). While some of the data tails away at the start and the end, this can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# https://www.statsmodels.org/stable/generated/statsmodels.graphics.gofplots.qqplot.html\n",
    "stats.probplot(sample, dist='norm', plot=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapiro-Wilks Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the Shapiro Wilk Test on the sample data \n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html\n",
    "shapiro_test = stats.shapiro(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shapiro-Wilk Test Statistic: {shapiro_test.statistic}\")\n",
    "print(f\"p-value: {shapiro_test.pvalue}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the P value is greater than 5% (0.05), this would lead me to reject the null hypothesis and shows me that the data has a normal distribution (https://builtin.com/data-science/shapiro-wilk-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "count, bins, _ = plt.hist(sample, bins=50, density=True, alpha=0.6,)\n",
    "plt.plot(bins, stats.norm.pdf(bins, mu, sigma))\n",
    "plt.title(\"Histogram showing Normal Distribution\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 \n",
    "\n",
    "## t-Test Calculation\n",
    "\n",
    "In task 3, we consider the following dataset containing resting heart rates for patients before and after embarking on a two-week exercise program.\n",
    "Patient ID 0 1 2 3 4 5 6 7 8 9 Before 63 68 70 64 74 67 70 57 66 65 After 64 64 68 64 73 70 72 54 61 63\n",
    "Calculate the t-statistic based on this data set, using Python. \n",
    "Compare it to the value given by scipy.stats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the Data frames for the before and after resting heart rates\n",
    "data = {'patient_id': [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 'before':[ 63, 68, 70, 64, 74, 67, 70, 57, 66, 65],\n",
    "        'after': [64, 64, 68, 64, 73, 70, 72, 54, 61, 63]}\n",
    "df = pd.DataFrame(data)    \n",
    "# show the dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the statistical details of the dataset\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above data, we can see the mean of both sets are within 1 of each other, but the standard deviations of both sets of data are different. To visualise this, we can create two plots of the data to show them individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out the dataframe to the before and after data\n",
    "Before = df['before']\n",
    "After = df['after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "# Create the Histogram for before exercising.\n",
    "ax[0].hist(Before, bins=10, color='blue', alpha=0.5)\n",
    "ax[0].set_title('Distribution of Heart Rate Before Exercising', fontsize=12)\n",
    "ax[0].set_xlabel('Before Exercising', fontsize=10)\n",
    "ax[0].set_ylabel('Frequency', fontsize=10)\n",
    "ax[0].grid(alpha=0.3)\n",
    "# Create the Histogram for after exercising.\n",
    "ax[1].hist(After, bins=10, color='red', alpha=0.5)\n",
    "ax[1].set_title('Distribution of Heart Rate After Exercising ', fontsize=12)\n",
    "ax[1].set_xlabel('After Exercising', fontsize=10)\n",
    "ax[1].set_ylabel('Frequency', fontsize=10)\n",
    "ax[1].grid(alpha=0.3)\n",
    "# Show the plots.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get another picture by using Strip plots. The advantage of these is the speed of creation using minimal code.\n",
    "\n",
    "[Strip Plots](https://www.geeksforgeeks.org/stripplot-using-seaborn-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(data=[Before, After])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the Strip plot that the mean of the data is nearly the same, the larger outlier is showing atthe bottom of the plot. We can see this better using boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=[Before, After])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the value using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.pythonpool.com/t-test-in-python/\n",
    "Before_bar, After_bar = np.mean(Before), np.mean(After) # calculate the mean\n",
    "n1, n2 = len(Before), len(After) # length of datasets\n",
    "var_Before, var_After= np.var(Before, ddof=1), np.var(After, ddof=1) # compute the spread\n",
    "var = ( ((n1-1)*var_Before) + ((n2-1)*var_After) ) / (n1+n2-2)\n",
    "std_error = np.sqrt(var * (1.0 / n1 + 1.0 / n2))\n",
    "  \n",
    "# calculate t statistics\n",
    "t = abs(Before_bar - After_bar) / std_error\n",
    "print('t statistic:',t)\n",
    "\n",
    "# calculate p value\n",
    "p_value = 2*(1-stats.t.cdf(x=t, df=12))\n",
    "print(\"p-value:\",p_value)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the P value using scipy stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(Before, After)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that to calculate the value using python numpy uses a lot more code, whereas scipy stats gives us nearly the same P value as an answer to allow us to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "\n",
    "## ANOVA\n",
    "In this test we will estimate the probability of committing a type II error in specific circumstances. To begin, we create a variable called no_type_ii and set it to 0.\n",
    "Then we use a loop to perform the following test 10,000 times.\n",
    "1.\tUse numpy.random.normal to generate three samples with 100 values each. Give each a standard deviation of 0.1. Give the first sample a mean of 4.9, the second a mean of 5.0, and the third a mean of 5.1.\n",
    "2.\tPerform one-way anova on the three samples and add 1 to no_type_ii whenever a type II error occurs.\n",
    "Summarize and explain the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A type i error occurs when we get false positive results, i.e. we conclude a drug improves symptoms in a patient when it doesn't and a type ii error is when we get false negative results i.e. we conclude a drug doesn't improve symptoms in a patient when it does.\n",
    "\n",
    "[Error types](https://www.scribbr.com/statistics/type-i-and-type-ii-errors/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://statistics.laerd.com/statistical-guides/one-way-anova-statistical-guide.php\n",
    "no_type_ii = 0\n",
    "\n",
    "# loop 10,000 times\n",
    "for _ in range(10001):\n",
    "# Create the three samples as stated in first part\n",
    "    sample_a = np.random.normal(4.9, 0.1, 100)\n",
    "    sample_b = np.random.normal(5.0, 0.1, 100)\n",
    "    sample_c = np.random.normal(5.1, 0.1, 100)\n",
    "    # perform one way ANOVA\n",
    "    f, p = stats.f_oneway(sample_a, sample_b, sample_c)\n",
    "    #Check if a type ii error  and add 1 to total\n",
    "    if p > 0.05:\n",
    "        no_type_ii += 1\n",
    "# print the results\n",
    "print(f'The loop ran {_} times') \n",
    "print(f'Type ii errors: {no_type_ii}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One way ANOVA Hypotheses\n",
    "https://statisticsbyjim.com/anova/one-way-anova/\n",
    "\n",
    "Instead of looking at each individual difference, ANOVA examines the ratio of variance between groups and the variance within groups to determine whether the ratio is big enough to be statistically significant. \n",
    "\n",
    "![image.png](images\\ANOVA.png)\n",
    "\n",
    "\n",
    "[hypothesis testing analysis of variance anova](https://medium.com/analytics-vidhya/hypothesis-testing-analysis-of-variance-anova-52c3df0fbc80)\n",
    "\n",
    "\n",
    "\n",
    "Null hypotheses: There is no difference between the means of the groups\n",
    "\n",
    "Alternative Hypothesis: There is a difference between the means of the groups but it does not show if it is one, or more groups, that have different means.\n",
    "\n",
    "We reject the null hypothesis when the p value is less than the significance level of 0.05. This shows the differences between the means are not statistically significant. As can be seen from the results, if p is greater than 0.05, the output will add one to the type ii errors count. I had 0 for this count so all the p values were below the point of significance, so we can reject the null hypothesis as we are shown that there is a significant difference in the means of the three groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
